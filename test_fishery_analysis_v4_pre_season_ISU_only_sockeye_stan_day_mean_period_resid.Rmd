---
title: Skagit Sockeye Test Fishery Data Exploration
author: Thomas Buehrens (tbuehrens@dfw.wa.gov) & Casey Ruff (cruff@swinomish.nsn.us)
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

***

Last Updated `r format(Sys.time(), '%m/%d/%Y')`.

***


# Overview
This script fits a regression model to Skagit Sockeye Test Fishery Data with Total Run Size as an offset. In years prior to the final year, the "observed" TRS is supplied as the offset. In the final In-Season-Update (ISU) year, the mean and sd of the preseason forecast are supplied as priors for the TRS. When this model is fit with no data for the final year, it returns exactly* the preseason forecast. As ISU test fishery data is added, the model progressively updates the pre-season forecast, providing an ISU estimate of runsize.

*the model will not produce EXACTLY the preseason forecast with no ISU data. It is using a log-normal distribution to approximate the probability density function of the pre-season forecast, which is very good but inexact so actual forecasts with no ISU data may vary by 1-2% of the "true" preseason forecast.

The code repository used to generate this page and complete analyses can be found here: [**(link)**](https://github.com/casruff/test_fishery_data_exploration)

## Setup
All analyses require R software [**(link)**](https://cran.r-project.org/) (v3.4.3) for data retrieval, data processing, and summarizing model results. Here we configure R to perform our analysis and generate our outputs
```{r set_options, echo = TRUE, message = FALSE}
options(width = 100)
knitr::opts_chunk$set(message = FALSE)
set.seed(123)
```

We also need a couple of helper functions which we will define
```{r load_funcs, message = FALSE, warning = FALSE,results = "hide"}
#function to install or load packages
install_or_load_pack <- function(pack){
  create.pkg <- pack[!(pack %in% installed.packages()[, "Package"])]
  if (length(create.pkg))
    install.packages(create.pkg, dependencies = TRUE)
  sapply(pack, require, character.only = TRUE)
}

```

Here we will load & install packages we need to use (needs internet connection if packages not already installed)
```{r load_packages, message = FALSE, warning = FALSE,results = "hide"}
packages_list<-c("tidyverse"
                 ,"forecast"
                 ,"mgcv"
                 ,"ggplot2"
                 ,"MASS"
                 ,"RColorBrewer"
                 ,"kableExtra"
                 ,"gtools"
                 ,"readr"
                 ,"here"
                 ,"readxl"
                 ,"brms"
                 ,"bsplus"
                 ,"lubridate"
                 ,"MuMIn"
                 ,"tidymv"
                 ,"modelr"
                 ,"R2jags"
                 ,"kableExtra"
                 ,"rstan"
                 # ,"rnoaa"
                 # ,"ncdf4"
                 # ,"ncdf4.helpers"
                 # ,"raster"
                 ,"reshape2"
                 # ,"ggfortify"
                 )
install_or_load_pack(pack = packages_list)
```

## User Inputs
Here we will specify the years of analysis, identify data file names and the flow gauge to be used.
```{r user_inputs, message = FALSE, warning = FALSE,results = "show"}
## set data dir
datadir <- here("data")
modeldir <- here("jags")

## first & last years of fish data
yr_frst <- 2010
yr_last <- 2022

#evaluation week
wk_eval <- 28


## data file names
## 1. file with escapement data
fn_trs <- "sockeye_trs.csv"

## 2. file with age comp data
fn_tst_fsh <- "skgt_sockeye_tst_fsh.csv"

## get flow data (currently using mainstem at mount vernon)
## flow gage ID
flow_site <- 12200500  
```

## Load Data
In this section we will load 1) the Total Run Size data, 2) the Test Fishery Data, and 3) The flow data.
```{r load_data, message = FALSE, warning = FALSE,results = "show"}
## read total runsize data
dat_trs <- read_csv(file.path(datadir,fn_trs))
## read in test fishery data
dat_tst_fsh <- read_csv(file.path(datadir,fn_tst_fsh))%>%
  mutate(date = mdy(date))



## get URL for flow data from USGS
flow_url <- paste0("https://waterdata.usgs.gov/nwis/dv",
                   "?cb_00060=on",
                   "&format=rdb",
                   "&site_no=",flow_site,
                   "&begin_date=",yr_frst,"-01-01",
                   "&end_date=",yr_last,"-12-31")

## raw flow data from USGS
skip <- read_lines(flow_url)%>%
  as_tibble()%>%
  filter(grepl("\\#",value))%>%
  summarise(skip=n())%>%
  unlist()

## flow data for years of interest
dat_flow <-  read_tsv(flow_url,
                      col_names = FALSE,
                      col_types = "ciDdc",
                      skip = skip + 2 )%>%
  dplyr::rename(date=X3,flow=X4)%>%
  dplyr::select(date,flow)%>%
  mutate(flow = flow / 35.3147,
         year= year(date),
         day = yday(date),
         month = month(date)
  )

```
## ARIMA model with preseason forecast 
This model estimates the Total Run Size (TRS) by predicting test fishery catch using regression model with the following equation:

catch ~ negative binomial (prediction, over-dispersion parameter) 

where

prediction = exp(intercept + random effect(site) + factor(set number) + random walk (day of year) + log(effort in seconds) + log(centered year effect))

The log(centered year effect) is given as data for all but the final incomplete year where TRS is unknown. It is calculated as the log(TRS) - log(mean(TRS[1:final_year-1])). The log(centered year effect) for the final incomplete year is given a normally distributed prior by subtracting log(mean(TRS[1:final_year-1])) from the log of a set of mcmc draws from the preseason forecast probability density function and calculating the mean and the sd of the resulting set of mcmc draws. Thus the model produces exactly* the preseason forecast when no new ISU data is provided for the final year, and then as ISU data is added, progressively updates this pre-season forecast providing ISU estimates of TRS.

*the model will not produce EXACTLY the preseason forecast with no ISU data. It is using a log-normal distribution to approximate the probability density function of the pre-season forecast, which is very good but inexact so actual forecasts with no ISU data may vary by 1-2% of the "true" preseason forecast.
```{r Analysis_pre_season, message=FALSE, warning=FALSE, results="show"}
dat<-dat_tst_fsh%>%
  left_join(dat_trs)%>%
  left_join(dat_flow)%>%
  mutate(site=factor(site),
         zl_flow=scale(log(flow)),
         effort = as.numeric(time_out-time_in)*60*60,
         )%>%
  filter(set_num < 10 )%>%
  rownames_to_column()%>%
  mutate(year = year - min(year) + 1,
         day = day - min(day,na.rm = TRUE) + 1,
         period = (year-1) * max(day,na.rm = TRUE) + day
         )%>%
  filter(!is.na(day))


dat <- rbind(dat%>%
  filter(year < max(year)),dat%>%
  filter(year == max(year) & week_num < 29))


forecast <- read_csv(file.path(datadir,"sockeyeforecast.csv"))%>% 
  mutate(log_F = log(Estimate),
         log_F_anom = log_F - dat_trs%>%filter(!is.na(trs) & year < max(year))%>%summarise(ml_trs=mean(log(trs)))%>%dplyr::select(ml_trs)%>%unlist()
  )%>%summarise(
     mu_log_forcast_anom = mean(log_F_anom),
     sd_log_forcast_anom = sd(log_F_anom)
  )

# ggplot(dat%>%
#          group_by(year,day,date)%>%
#          summarise(effort=sum(effort),SockeyeC=sum(SockeyeC))
#        ,aes(x=date,y=SockeyeC,group=factor(year)))+
#   facet_wrap(~year,ncol=1,scales="free_x")+
#   geom_line()+
#   geom_point()  

standat<-list(
  S = max(dat$day,na.rm = TRUE) - min(dat$day, na.rm = TRUE) + 1,
  Y = max(dat$year) - min(dat$year) + 1,
  #sites = length(unique(dat$site)),
  netsets = length(unique(dat$set_num)),
  #site = as.numeric(dat$site),
  set_num = as.numeric(dat$set_num),
  effort = dat$effort/(60*60),#convert effort to hours
  zl_flow = dat%>%ungroup()%>%dplyr::select(zl_flow)%>%unlist,
  ##====================================================
  # run with these turned on to show in-season forecast
  #=====================================================
  obs = dat%>%nrow(),
  SockeyeC = dat%>%ungroup()%>%dplyr::select(SockeyeC)%>%unlist(),
  year = dat%>%ungroup()%>%dplyr::select(year)%>%unlist(),
  day = dat%>%ungroup()%>%dplyr::select(day)%>%unlist(),
  period = dat%>%ungroup()%>%dplyr::select(period)%>%unlist(),
  ##====================================================
  # run with these turned on to show pre-season forecast
  #=====================================================
  # obs = dat%>%filter(year<max(year))%>%nrow(),
  # Sockeye = dat%>%filter(year<max(year))%>%dplyr::select(SockeyeC)%>%unlist(),
  # year = dat%>%filter(year<max(year))%>%dplyr::select(year)%>%unlist(),
  # day = dat%>%filter(year<max(year))%>%dplyr::select(day)%>%unlist(),
  # period = dat%>%filter(year<max(year))%>%dplyr::select(period)%>%unlist(),
  #======================================================
  Y_obs = length(unique(dat$year)),
  ylist = unique(dat$year),
  log_trs_anom = dat_trs%>%filter(!is.na(trs) & year < max(year))%>%mutate(log_trs_anom =log(trs) - mean(log(trs)))%>%dplyr::select(log_trs_anom)%>%unlist(),
  mu_log_forcast_anom = forecast$mu_log_forcast_anom,
  sd_log_forcast_anom = forecast$sd_log_forcast_anom
)


if(!file.exists("results/fit_pre_season_sockeye_stan_day_mean_period_resid.RDS")){
  start<-Sys.time()
  print(start)
  model<-stan_model("stan/model_pre_season_sockeye_day_mean_period_resid.stan")
  fit<-sampling(
    object=model,
    data=standat,
    cores = 4,
    chains=4,
    iter=1000,
    warmup = 500,
    thin = 1,
    control = list(
      adapt_delta = 0.95
    )
  )
  stop<-Sys.time()
  print(stop-start)
  write.csv(summary(fit)$summary,"results/summary_pre_season_sockeye_stan_day_mean_period_resid.csv")
  saveRDS(fit,"results/fit_pre_season_sockeye_stan_day_mean_period_resid.RDS")
}else{
  fit<-readRDS("results/fit_pre_season_sockeye_stan_day_mean_period_resid.RDS")
}

ml_trs=dat_trs%>%filter(!is.na(trs) & year < max(year))%>%summarise(ml_trs = mean(log(trs)))%>%dplyr::select(ml_trs)%>%unlist()

abundance<-tibble(melt(extract(fit)$b3))%>%
  dplyr::rename(draw=iterations,year=Var2,value=value)%>%
  mutate(abundance = exp(value + ml_trs))%>%
  group_by(year)%>%
  summarise(abundance = quantile(abundance, c(0.025, 0.25, 0.5, 0.75,0.975)), q = c(0.025, 0.25, 0.5, 0.75,0.975))%>%
  pivot_wider(id_cols=year,names_from = q,values_from = abundance)%>%
  mutate(year= year + min(dat_tst_fsh$year)-1)%>%
  left_join(dat_trs%>%dplyr::select(year=year,trs)%>%group_by(year)%>%summarise(trs=first(trs)))

ggplot(abundance,aes(x=year,y=trs))+
  geom_ribbon(mapping = aes(x=year,ymin =`0.025`, ymax = `0.975`),alpha=0.25,fill="red")+
  geom_ribbon(mapping = aes(x=year,ymin =`0.25`, ymax = `0.75`),alpha=0.25,fill="red")+
  geom_line(mapping=aes(x=year,y=`0.5`),color="red")+
  geom_point()+
  ylim(0,NA)

abundance%>%
  dplyr::select(year,trs,`0.025`,`0.25`, `0.5`,`0.75`,`0.975`)%>%
  ungroup()%>%
  dplyr::select(!trs)%>%
  filter(year == max(year))%>%
  kbl(caption = "Table 1. In-Season-Update of Predicted TRS",digits =0)%>%
  kable_classic(full_width = F, html_font = "Cambria")

day_effect<-tibble(melt(extract(fit)$day_pct))%>%
  rename(draw=iterations,year=Var2,day=Var3,day_effect=value)%>%
  group_by(year,day)%>%
  mutate(year= year + min(dat_tst_fsh$year)-1, day=day+min(yday(dat$date))-1)%>%
  summarise(day_effect = quantile(day_effect, c(0.025, 0.25, 0.5, 0.75,0.975)), q = c(0.025, 0.25, 0.5, 0.75,0.975))%>%
  pivot_wider(id_cols=c(year,day),names_from = q,values_from = day_effect)

ggplot(day_effect,aes(x=day,y=`0.5`,group=year))+
  ylab("% of season total run passing the test fishery by day")+
  xlab("Day of Year")+
  facet_wrap(~year)+
  geom_ribbon(mapping = aes(x=day,ymin =`0.025`, ymax = `0.975`),alpha=0.25,fill="red")+
  geom_ribbon(mapping = aes(x=day,ymin =`0.25`, ymax = `0.75`),alpha=0.25,fill="red")+
  geom_line(mapping=aes(x=day,y=`0.5`),color="red")+
  geom_point()+
  scale_y_log10(labels = scales::percent, limits=c(0.0001,.50))
  #scale_y_continuous(labels = scales::percent, limits=c(0.0001,.50))
  #ylim(0.001,.2)

# day_resid<-tibble(melt(extract(fit)$resid_period))%>%
#   rename(draw=iterations,period=Var2,day_resid=value)%>%
#   group_by(period)%>%
#   summarise(day_resid= quantile(day_resid, c(0.025, 0.25, 0.5, 0.75,0.975)), q = c(0.025, 0.25, 0.5, 0.75,0.975))%>%
#   pivot_wider(id_cols=c(period),names_from = q,values_from = day_resid)
#   
# ggplot(day_resid,aes(x=period,y=`0.5`))+
#   ylab("residual")+
#   xlab("Day of Year")+
#   geom_ribbon(mapping = aes(x=period,ymin =`0.025`, ymax = `0.975`),alpha=0.25,fill="red")+
#   geom_ribbon(mapping = aes(x=period,ymin =`0.25`, ymax = `0.75`),alpha=0.25,fill="red")+
#   geom_line(mapping=aes(x=period,y=`0.5`),color="red")+
#   geom_point()
```
