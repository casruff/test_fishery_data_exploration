---
title: Skagit Steelhead Test Fishery Data Exploration
author: Thomas Buehrens (tbuehrens@dfw.wa.gov) & Casey Ruff (cruff@swinomish.nsn.us)
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

***

Last Updated `r format(Sys.time(), '%m/%d/%Y')`.

***


# Overview
This script fits Generalized Additive Models to Skagit Steelhead Test Fishery Data with and without the Total Run Size as an offset. The best model without TRS as an offset includes a spline term for year, which attempts to explain the residual variance (e.g., due to interannual run size differences) when the TRS offset is removed. Therefore, this spline term may be considered somewhat analogous to the model's ability to predict runsize based on the in-season test fishery data. A prediction of Total Run Size may be obtained by multiplying this fitted value of this year term (holding all other terms to zero) by the mean annual run size. Predictions from this approach, including 95%CI are compared with observed TRS, demonstrating the efficacy of using in-season test fishery data to estimate Total Run Size.

The code repository used to generate this page and complete analyses can be found here: [**(link)**](https://github.com/casruff/test_fishery_data_exploration)

## Setup
All analyses require R software [**(link)**](https://cran.r-project.org/) (v3.4.3) for data retrieval, data processing, and summarizing model results. Here we configure R to perform our analysis and generate our outputs
```{r set_options, echo = TRUE, message = FALSE}
options(width = 100)
knitr::opts_chunk$set(message = FALSE)
set.seed(123)
```

We also need a couple of helper functions which we will define
```{r load_funcs, message = FALSE, warning = FALSE,results = "hide"}
#function to install or load packages
install_or_load_pack <- function(pack){
  create.pkg <- pack[!(pack %in% installed.packages()[, "Package"])]
  if (length(create.pkg))
    install.packages(create.pkg, dependencies = TRUE)
  sapply(pack, require, character.only = TRUE)
}

```

Here we will load & install packages we need to use (needs internet connection if packages not already installed)
```{r load_packages, message = FALSE, warning = FALSE,results = "hide"}
packages_list<-c("tidyverse"
                 ,"forecast"
                 ,"mgcv"
                 ,"ggplot2"
                 ,"MASS"
                 ,"RColorBrewer"
                 ,"kableExtra"
                 ,"gtools"
                 ,"readr"
                 ,"here"
                 ,"readxl"
                 ,"brms"
                 ,"bsplus"
                 ,"lubridate"
                 ,"MuMIn"
                 ,"tidymv"
                 ,"modelr"
                 ,"R2jags"
                 ,"kableExtra"
                 # ,"rnoaa"
                 # ,"ncdf4"
                 # ,"ncdf4.helpers"
                 # ,"raster"
                 ,"reshape2"
                 # ,"ggfortify"
                 )
install_or_load_pack(pack = packages_list)
```

## User Inputs
Here we will specify the years of analysis, identify data file names and the flow gauge to be used.
```{r user_inputs, message = FALSE, warning = FALSE,results = "show"}
## set data dir
datadir <- here("data")
modeldir <- here("jags")

## first & last years of fish data
yr_frst <- 2013
yr_last <- 2022


## data file names
## 1. file with escapement data
fn_trs <- "sthd_trs.csv"

## 2. file with age comp data
fn_tst_fsh <- "skgt_sthd_tst_fsh_update.csv"

## get flow data (currently using mainstem at mount vernon)
## flow gage ID
flow_site <- 12200500  
```

## Load Data
In this section we will load 1) the Total Run Size data, 2) the Test Fishery Data, and 3) The flow data.
```{r load_data, message = FALSE, warning = FALSE,results = "show"}
## read total runsize data
dat_trs <- read_csv(file.path(datadir,fn_trs))
## read in test fishery data
dat_tst_fsh <- read_csv(file.path(datadir,fn_tst_fsh))%>%
  mutate(date = mdy(date))



## get URL for flow data from USGS
flow_url <- paste0("https://waterdata.usgs.gov/nwis/dv",
                   "?cb_00060=on",
                   "&format=rdb",
                   "&site_no=",flow_site,
                   "&begin_date=",yr_frst,"-01-01",
                   "&end_date=",yr_last,"-12-31")

## raw flow data from USGS
skip <- read_lines(flow_url)%>%
  as_tibble()%>%
  filter(grepl("\\#",value))%>%
  summarise(skip=n())%>%
  unlist()

## flow data for years of interest
dat_flow <-  read_tsv(flow_url,
                      col_names = FALSE,
                      col_types = "ciDdc",
                      skip = skip + 2 )%>%
  dplyr::rename(date=X3,flow=X4)%>%
  dplyr::select(date,flow)%>%
  mutate(flow = flow / 35.3147,
         year= year(date),
         day = yday(date),
         month = month(date)
  )

```

## Analysis by set (only using set 1 & 2)
Here we will combine the three datasets, fit a series of gam models with spline terms for day of year, an interaction between site and day of year, and flow, and fit random effects for site and set number. Here the response variable is catch per per net set. Offset terms include the number of seconds per net set and the Total Run Size. Once a "best model" is fit, the best model is refit dropping the offset for Total Runsize and then used to predict total run size. Predictions are compared with observations. 

Results shown include:
1) the model selection table 
2) the summary statistics for the best model
3) plots of the spline terms on the link scale for the best model
4) the "gam.check" plots for goodness of fit and GOF statistics table
5) The model selection table including the best model re-fit without the TRS offset
6) a plot of the predicted relative CPUE by day of year for an average year from the best model
7) the best model's forecast of TRS compared with observations
```{r Analysis, message = FALSE, warning = FALSE,results = "show"}
dat<-dat_tst_fsh%>%
  left_join(dat_trs)%>%
  left_join(dat_flow)%>%
  mutate(site=factor(site),
         zl_flow=scale(log(flow)),
         effort = as.numeric(time_out-time_in),
         lm_trs = log(mean(unique(trs),na.rm = TRUE))
         )%>%
  filter(set_num < 3 )#%>%
  #group_by(year,day,site,flow)%>%
  #summarise(SthdW = sum(SthdW),
  #          effort = sum(effort)      
  #          )
  
  write.csv(dat, file = paste(datadir,"/dat.csv",sep = ""))


m1<-gam(SthdW ~  s(day) + s(site,bs="re"), offset = log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m2<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m3<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(set_num,bs="re"), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m4<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(set_num,bs="re")  + s(day,site,bs="fs"), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m5<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(set_num,bs="re")   + s(day,site,bs="fs") +  s(year,k=7,bs="ps",m=1), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)


model.sel(m1,m2,m3,m4,m5)


summary(m3)
plot(m3)
gam.check(m3)
plot(m3$y~ m3$fitted.values)
abline(a=0,b=1)

#best model removing offset of total run size, adding a year spline...this term should explain variance accounted for previously by offset term

m3b<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(set_num,bs="re") + s(year,k=7,bs="ps",m=1), offset = log(effort) + lm_trs,  family = nb(theta = NULL, link = "log"),data=dat)
#model with year as factor
# m3c<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(set_num,bs="re") + as.factor(year), offset = log(effort) + lm_trs,  family = nb(theta = NULL, link = "log"),data=dat)


model.sel(m1,m2,m3,m4,m5,m3b)

#what does year spline term look like?
# plot(m3b,select = 5,shade=T)

#add a relative CPUE plot
newdat<-expand.grid(day=seq(33,120,1),
                    site="Cable",
                    year=2014,
                    set_num = 1,
                    zl_flow = 0,
                    effort = 1000,
                    trs = 9334
                    )%>%
  as.tibble()%>%
  add_predictions(m3,var="pred")%>%
  mutate(pred = exp(pred + log(effort) + log(trs)))%>%
  mutate(relative_CPUE = pred/max(pred))

ggplot(newdat,aes(x=day,y=relative_CPUE))+
  geom_line()+
  ylim(0,1)

#what does model predict trs is each year?
newdat<-dat_trs%>%
  mutate(day=NA,
         site = NA,
         effort = NA,
         zl_flow = NA,
         SthdW = NA,
         )%>%
  filter(year!=2018)

preds_yr<-predict.gam(m3b, newdata=newdat, type = "terms", exclude = c("s(day)","s(site)","s(zl_flow)","s(set_num)"), newdata.guaranteed=TRUE, se.fit=T)

preds<-data.frame(mle=c(exp(preds_yr$fit) *  exp(unique(dat$lm_trs))),#multiply by mean or geomean?
                  l95=c(exp(preds_yr$fit - 1.96 * preds_yr$se) *  exp(unique(dat$lm_trs))),
                  u95=c(exp(preds_yr$fit + 1.96 * preds_yr$se) *  exp(unique(dat$lm_trs)))
)


newdat<-newdat%>%
  bind_cols(preds)
  

ggplot(data=newdat,aes(x=year, y=trs))+
  geom_ribbon(mapping=aes(x=year,ymin=l95,ymax=u95),fill="blue",color=NA,alpha=0.5)+
  geom_line(mapping=aes(x=year,y=mle),color="blue")+
  geom_point(size=2)+
  geom_point(mapping=aes(x=year,y=mle),size=1.3, color ="blue")+
  ylim(0,NA)

newdat%>%
  dplyr::select(year,trs,mle,l95,u95)%>%
  kbl(caption = "Table 1. Predicted vs. observed TRS",digits =0)%>%
  kable_classic(full_width = F, html_font = "Cambria")
```

## Analysis by date/location (pooling sets)
Here we will combine the three datasets, fit a series of gam models with spline terms for day of year, an interaction between site and day of year, and flow, and fit random effects for site. Here the response variable is catch per day and location rather than per net set. Offset terms include the number of seconds per net set and the Total Run Size. Once a "best model" is fit, the best model is refit dropping the offset for Total Runsize and then used to predict total run size. Predictions are compared with observations.

Results shown include:
1) the model selection table 
2) the summary statistics for the best model
3) plots of the spline terms on the link scale for the best model
4) the "gam.check" plots for goodness of fit and GOF statistics table
5) The model selection table including the best model re-fit without the TRS offset
6) the best model's forecast of TRS compared with observations
```{r Analysis_v2, message = FALSE, warning = FALSE,results = "show"}
dat<-dat_tst_fsh%>%
  left_join(dat_trs)%>%
  left_join(dat_flow)%>%
  mutate(site=factor(site),
         zl_flow=scale(log(flow)),
         effort = as.numeric(time_out-time_in),
         lm_trs = log(mean(unique(trs),na.rm = TRUE))
         )%>% filter(set_num < 7)%>%
  group_by(year,day,site,zl_flow,lm_trs,trs)%>%
  summarise(SthdW = sum(SthdW),
           effort = sum(effort),
           lm_trs = first(lm_trs))
  
  dat %>% filter(year == 2022) %>% head()
  
  write.csv(dat, file = paste(datadir,"/dat.csv",sep = ""))


m1<-gam(SthdW ~  s(day) + s(site,bs="re"), offset = log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m2<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m3<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(day,site,bs="fs"), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)

m4<-gam(SthdW ~  s(day) + s(site,bs="re") + s(zl_flow) + s(day,site,bs="fs") +  s(year,k=7,bs="ps",m=1), offset=log(trs) + log(effort), family = nb(theta = NULL, link = "log"),data=dat)


model.sel(m1,m2,m3,m4)


summary(m1)
plot(m1)
gam.check(m1)
plot(m1$y~ m1$fitted.values)
abline(a=0,b=1)
#best model removing offset of total run size, adding a year spline...this term should explain variance accounted for previously by offset term

m1b<-gam(SthdW ~  s(day) + s(site,bs="re") + s(year,k=7,bs="ps",m=1), offset = log(effort) + lm_trs,  family = nb(theta = NULL, link = "log"),data=dat)



#model with fixed effect for year
# m1c<-gam(SthdW ~  s(day) + s(site,bs="re") + as.factor(year), offset = log(effort) + lm_trs,  family = nb(theta = NULL, link = "log"),data=dat)


model.sel(m1,m2,m3,m4,m1b)

#what does year spline term look like?
# plot(m1b,select = 3,shade=T)

#what does model predict trs is each year?
newdat<-dat_trs%>%
  mutate(day=NA,
         site = NA,
         effort = NA,
         zl_flow = NA,
         SthdW = NA,
         )%>%
  filter(year!=2018)

preds_yr<-predict.gam(m1b, newdata=newdat, type = "iterms", exclude = c("s(day)","s(site)"), newdata.guaranteed=TRUE, se.fit=T)

preds<-data.frame(mle=c(exp(preds_yr$fit) *  exp(unique(dat$lm_trs))),#multiply by mean or geomean?
                  l95=c(exp(preds_yr$fit - 1.96 * preds_yr$se) *  exp(unique(dat$lm_trs))),
                  u95=c(exp(preds_yr$fit + 1.96 * preds_yr$se) *  exp(unique(dat$lm_trs)))
)


newdat<-newdat%>%
  bind_cols(preds)
  

ggplot(data=newdat,aes(x=year, y=trs))+
  geom_ribbon(mapping=aes(x=year,ymin=l95,ymax=u95),fill="blue",color=NA,alpha=0.5)+
  geom_line(mapping=aes(x=year,y=mle),color="blue")+
  geom_point(size=2)+
  geom_point(mapping=aes(x=year,y=mle),size=1.3, color ="blue")+
  ylim(0,NA)

newdat%>%
  dplyr::select(year,trs,mle,l95,u95)%>%
  kbl(caption = "Table 2. Predicted vs. observed TRS",digits =0)%>%
  kable_classic(full_width = F, html_font = "Cambria")
```

## Trying out some count ARIMA models
```{r Analysis_v3, message=FALSE, warning=FALSE, results="show"}
dat<-dat_tst_fsh%>%
  left_join(dat_trs)%>%
  left_join(dat_flow)%>%
  mutate(site=factor(site),
         zl_flow=scale(log(flow)),
         effort = as.numeric(time_out-time_in)*60*60,
         lm_trs = log(mean(unique(trs),na.rm = TRUE))
         )%>%
  filter(set_num < 3 )%>%
  add_rownames()%>%
  mutate(year = year - min(year)  +1,
         day = day - min(day,na.rm = TRUE) + 1,
         period = (year-1) * max(day,na.rm = TRUE) + day
         )%>%
  filter(!is.na(day))

jagsdat<-list(
  S = max(dat$day,na.rm = TRUE) - min(dat$day, na.rm = TRUE) + 1,
  Y = max(dat$year) - min(dat$year) + 1,
  sites = length(unique(dat$site)),
  netsets = length(unique(dat$set_num)),
  site = as.numeric(dat$site),
  set_num = as.numeric(dat$set_num),
  effort = dat$effort/(60*60),
  lm_trs = dat$lm_trs,
  obs = length(as.numeric(dat$rowname)),
  SthdW = dat$SthdW,
  year = dat$year,
  day = dat$day,
  period = dat$period,
  Y_obs = length(unique(dat$year)),
  ylist = unique(dat$year)
)

model<-"model
{
  #Data
  # S number of periods in season
  # Y number of years
  # sites number of sites
  # netsets max number of net sets
  # site site for each obs
  # set_num set number for each obs
  # effort effort in hrs
  # lm_trs log(mean(total run size)) 
  # obs  observation number
  # SthdW wild steelhead catch
  # year year index for obs
  # ylist list of unique year indexes
  
  #Process Model
  for(i in 2:S){
    eps[i-1] ~ dnorm(0,1^-1)
    resid[i] = resid[i-1] + eps[i-1] * sigma
  }
  
  #Likelihood
  for(i in 1:obs){
    log_lambda[i] = b1[site[i]] + b2[set_num[i]] + log(effort[i]) + b3[year[i]] + resid[day[i]]
    p[i] <- r / (r + exp(log_lambda[i]))
    SthdW[i] ~ dnegbin(p[i], r)
  }
  
  #Priors
  sigma ~ dt(0,2.5^-2,1) T(0,)
  sigma_disp ~ dt(0,2.5^-2,1) T(0,)
  r = sigma_disp^-2 #negative binomial overdispersion parameter
  b1[1] = 0;
  b2[1] = 0;
  b3[1] = 0;
  resid[1] ~ dnorm(0,10^-2)
  for(i in 2:sites){
    b1[i] ~ dnorm(0,5^-2)
  }  
  for(i in 2:netsets){
    b2[i] ~ dnorm(0,5^-2) 
  }
  for(i in 2:Y_obs){
    b3[ylist[i]] ~ dnorm(0,2^-2)
  }
}"

write(model,"jags/model_v3.txt")  

  
params=c(
  "sigma",
  "phi1",
  "sigma_disp",
  "r",
  "p",
  "b1",
  "b2",
  "b3",
  "resid",
  "eps",
  "mu",
  "log_lambda"
)

if(!file.exists("results/fit_v3.RDS")){
  start<-Sys.time()
  print(start)
  fit<-jags.parallel(
    data=jagsdat,
    inits=NULL,
    parameters.to.save = params,
    model.file = "jags/model_v3.txt",
    n.chains = 4,
    n.iter = 2000,
    n.burnin = 1000,
    n.thin = 1
  )
  stop<-Sys.time()
  print(stop-start)
  write.csv(fit$BUGSoutput$summary,"results/summary_v3.csv")
  saveRDS(fit,"results/fit_v3.RDS")
}else{
  fit<-readRDS("results/fit_v3.RDS")
}


abundance<-tibble(melt(exp(fit$BUGSoutput$sims.list$b3 - apply(fit$BUGSoutput$sims.list$b3,2,mean) + unique(dat$lm_trs))))%>%
  rename(draw=Var1,year=Var2,abundance=value)%>%
  group_by(year)%>%
  summarise(abundance = quantile(abundance, c(0.025, 0.25, 0.5, 0.75,0.975)), q = c(0.025, 0.25, 0.5, 0.75,0.975))%>%
  pivot_wider(id_cols=year,names_from = q,values_from = abundance)%>%
  bind_cols(dat%>%dplyr::select(year_real=year,trs)%>%group_by(year_real)%>%summarise(trs=first(trs)))%>%
  dplyr::select(!year)%>%
  mutate(year= year_real + min(dat_tst_fsh$year)-1)

ggplot(abundance,aes(x=year,y=trs))+
  geom_ribbon(mapping = aes(x=year,ymin =`0.025`, ymax = `0.975`),alpha=0.25,fill="red")+
  geom_ribbon(mapping = aes(x=year,ymin =`0.25`, ymax = `0.75`),alpha=0.25,fill="red")+
  geom_line(mapping=aes(x=year,y=`0.5`),color="red")+
  geom_point()+
  ylim(0,NA)

abundance%>%
  dplyr::select(year,trs,`0.025`,`0.25`, `0.5`,`0.75`,`0.975`)%>%
  kbl(caption = "Table 3. Predicted vs. observed TRS",digits =0)%>%
  kable_classic(full_width = F, html_font = "Cambria")
```
